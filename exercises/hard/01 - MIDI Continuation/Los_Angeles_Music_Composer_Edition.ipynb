{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Los Angeles Music Composer Edition (ver. 4.0)\n",
        "\n",
        "***\n",
        "\n",
        "Powered by tegridy-tools: https://github.com/asigalov61/tegridy-tools\n",
        "\n",
        "***\n",
        "\n",
        "WARNING: This complete implementation is a functioning model of the Artificial Intelligence. Please excercise great humility, care, and respect. https://www.nscai.gov/\n",
        "\n",
        "***\n",
        "\n",
        "#### Project Los Angeles\n",
        "\n",
        "#### Tegridy Code 2023\n",
        "\n",
        "***"
      ],
      "metadata": {
        "id": "gpy3qsulqHa5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# (GPU CHECK)"
      ],
      "metadata": {
        "id": "W_So4w8fqPGL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X3rABEpKCO02",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title NVIDIA GPU check\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# (SETUP ENVIRONMENT)"
      ],
      "metadata": {
        "id": "C0XxnXGFqVyh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vK40g6V_BTNj",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Install dependencies\n",
        "!git clone --depth 1 https://github.com/asigalov61/Los-Angeles-Music-Composer\n",
        "!pip install torch\n",
        "!pip install einops\n",
        "!pip install torch-summary\n",
        "!pip install tqdm\n",
        "!pip install matplotlib\n",
        "!apt install fluidsynth #Pip does not work for some reason. Only apt works\n",
        "!pip install midi2audio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DzCOZU_gBiQV",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Import modules\n",
        "\n",
        "print('=' * 70)\n",
        "print('Loading core Los Angeles Music Composer modules...')\n",
        "\n",
        "import os\n",
        "import pickle\n",
        "import random\n",
        "import secrets\n",
        "import statistics\n",
        "from time import time\n",
        "import tqdm\n",
        "\n",
        "print('=' * 70)\n",
        "print('Loading main Los Angeles Music Composer modules...')\n",
        "import torch\n",
        "\n",
        "%cd /content/Los-Angeles-Music-Composer\n",
        "\n",
        "import TMIDIX\n",
        "\n",
        "from lwa_transformer import *\n",
        "\n",
        "%cd /content/\n",
        "print('=' * 70)\n",
        "print('Loading aux Los Angeles Music Composer modeules...')\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from torchsummary import summary\n",
        "from sklearn import metrics\n",
        "\n",
        "from midi2audio import FluidSynth\n",
        "from IPython.display import Audio, display\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "print('=' * 70)\n",
        "print('Done!')\n",
        "print('Enjoy! :)')\n",
        "print('=' * 70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eI3aQtHzqSnp"
      },
      "source": [
        "# (LOAD MODEL)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Unzip Pre-Trained Los Angeles Music Composer Model\n",
        "print('=' * 70)\n",
        "%cd /content/Los-Angeles-Music-Composer/Model\n",
        "\n",
        "print('=' * 70)\n",
        "print('Unzipping pre-trained Los Angeles Music Composer model...Please wait...')\n",
        "\n",
        "!cat /content/Los-Angeles-Music-Composer/Model/Los_Angeles_Music_Composer_Trained_Model.zip* > /content/Los-Angeles-Music-Composer/Model/Los_Angeles_Music_Composer_Trained_Model.zip\n",
        "print('=' * 70)\n",
        "\n",
        "!unzip -j /content/Los-Angeles-Music-Composer/Model/Los_Angeles_Music_Composer_Trained_Model.zip\n",
        "print('=' * 70)\n",
        "\n",
        "print('Done! Enjoy! :)')\n",
        "print('=' * 70)\n",
        "%cd /content/\n",
        "print('=' * 70)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "SqbxcFYVq63r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rDquonbXC2je",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Load Los Angeles Music Composer Model\n",
        "full_path_to_model_checkpoint = \"/content/Los-Angeles-Music-Composer/Model/Los_Angeles_Music_Composer_Model_88835_steps_0.643_loss.pth\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown Model precision option\n",
        "\n",
        "model_precision = \"bfloat16\" # @param [\"bfloat16\", \"float16\", \"float32\"]\n",
        "\n",
        "#@markdown bfloat16 == Third precision/triple speed (if supported, otherwise the model will default to float16)\n",
        "\n",
        "#@markdown float16 == Half precision/double speed\n",
        "\n",
        "#@markdown float32 == Full precision/normal speed\n",
        "\n",
        "plot_tokens_embeddings = False # @param {type:\"boolean\"}\n",
        "\n",
        "print('=' * 70)\n",
        "print('Loading Los Angeles Music Composer Pre-Trained Model...')\n",
        "print('Please wait...')\n",
        "print('=' * 70)\n",
        "print('Instantiating model...')\n",
        "\n",
        "torch.backends.cuda.matmul.allow_tf32 = True # allow tf32 on matmul\n",
        "torch.backends.cudnn.allow_tf32 = True # allow tf32 on cudnn\n",
        "device_type = 'cuda'\n",
        "\n",
        "if model_precision == 'bfloat16' and torch.cuda.is_bf16_supported():\n",
        "  dtype = 'bfloat16'\n",
        "else:\n",
        "  dtype = 'float16'\n",
        "\n",
        "if model_precision == 'float16':\n",
        "  dtype = 'float16'\n",
        "\n",
        "if model_precision == 'float32':\n",
        "  dtype = 'float32'\n",
        "\n",
        "ptdtype = {'float32': torch.float32, 'bfloat16': torch.bfloat16, 'float16': torch.float16}[dtype]\n",
        "ctx = torch.amp.autocast(device_type=device_type, dtype=ptdtype)\n",
        "\n",
        "SEQ_LEN = 4096\n",
        "\n",
        "# instantiate the model\n",
        "\n",
        "model = LocalTransformer(\n",
        "    num_tokens = 2831,\n",
        "    dim = 1024,\n",
        "    depth = 36,\n",
        "    causal = True,\n",
        "    local_attn_window_size = 512,\n",
        "    max_seq_len = SEQ_LEN\n",
        ")\n",
        "\n",
        "model = torch.nn.DataParallel(model)\n",
        "\n",
        "model.cuda()\n",
        "print('=' * 70)\n",
        "\n",
        "print('Loading model checkpoint...')\n",
        "\n",
        "model.load_state_dict(torch.load(full_path_to_model_checkpoint))\n",
        "print('=' * 70)\n",
        "\n",
        "model.eval()\n",
        "\n",
        "print('Done!')\n",
        "print('=' * 70)\n",
        "\n",
        "print('Model will use', dtype, 'precision...')\n",
        "print('=' * 70)\n",
        "\n",
        "# Model stats\n",
        "print('Model summary...')\n",
        "summary(model)\n",
        "\n",
        "# Plot Token Embeddings\n",
        "\n",
        "if plot_tokens_embeddings:\n",
        "  tok_emb = model.module.token_emb.weight.detach().cpu().tolist()\n",
        "\n",
        "  cos_sim = metrics.pairwise_distances(\n",
        "    tok_emb, metric='cosine'\n",
        "  )\n",
        "  plt.figure(figsize=(7, 7))\n",
        "  plt.imshow(cos_sim, cmap=\"inferno\", interpolation=\"nearest\")\n",
        "  im_ratio = cos_sim.shape[0] / cos_sim.shape[1]\n",
        "  plt.colorbar(fraction=0.046 * im_ratio, pad=0.04)\n",
        "  plt.xlabel(\"Position\")\n",
        "  plt.ylabel(\"Position\")\n",
        "  plt.tight_layout()\n",
        "  plt.plot()\n",
        "  plt.savefig(\"/content/Los-Angeles-Music-Composer-Tokens-Embeddings-Plot.png\", bbox_inches=\"tight\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# (LOAD SEED MIDI)"
      ],
      "metadata": {
        "id": "Gt03VtO6uKkb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Load Seed MIDI\n",
        "\n",
        "#@markdown Press play button to to upload your own seed MIDI or to load one of the provided sample seed MIDIs from the dropdown list below\n",
        "\n",
        "select_seed_MIDI = \"Upload your own custom MIDI\" #@param [\"Upload your own custom MIDI\", \"Los-Angeles-Music-Composer-Piano-Seed-1\", \"Los-Angeles-Music-Composer-Piano-Seed-2\", \"Los-Angeles-Music-Composer-Piano-Seed-3\", \"Los-Angeles-Music-Composer-Piano-Seed-4\", \"Los-Angeles-Music-Composer-Piano-Seed-5\", \"Los-Angeles-Music-Composer-MI-Seed-1\", \"Los-Angeles-Music-Composer-MI-Seed-2\", \"Los-Angeles-Music-Composer-MI-Seed-3\", \"Los-Angeles-Music-Composer-MI-Seed-4\", \"Los-Angeles-Music-Composer-MI-Seed-5\"]\n",
        "number_of_prime_tokens = 300 #@param {type:\"slider\", min:126, max:3000, step:3}\n",
        "render_MIDI_to_audio = False # @param {type:\"boolean\"}\n",
        "\n",
        "print('=' * 70)\n",
        "print('Los Angeles Music Composer Seed MIDI Loader')\n",
        "print('=' * 70)\n",
        "\n",
        "f = ''\n",
        "\n",
        "if select_seed_MIDI != \"Upload your own custom MIDI\":\n",
        "  print('Loading seed MIDI...')\n",
        "  f = '/content/Los-Angeles-Music-Composer/Seeds/'+select_seed_MIDI+'.mid'\n",
        "  score = TMIDIX.midi2single_track_ms_score(open(f, 'rb').read(), recalculate_channels=False)\n",
        "\n",
        "else:\n",
        "  print('Upload your own custom MIDI...')\n",
        "  print('=' * 70)\n",
        "  uploaded_MIDI = files.upload()\n",
        "  if list(uploaded_MIDI.keys()):\n",
        "    score = TMIDIX.midi2single_track_ms_score(list(uploaded_MIDI.values())[0], recalculate_channels=False)\n",
        "    f = list(uploaded_MIDI.keys())[0]\n",
        "\n",
        "if f != '':\n",
        "\n",
        "  print('=' * 70)\n",
        "  print('File:', f)\n",
        "  print('=' * 70)\n",
        "\n",
        "  #=======================================================\n",
        "  # START PROCESSING\n",
        "\n",
        "  # INSTRUMENTS CONVERSION CYCLE\n",
        "  events_matrix = []\n",
        "  melody_chords_f = []\n",
        "  melody_chords_f1 = []\n",
        "\n",
        "  itrack = 1\n",
        "\n",
        "  patches = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
        "\n",
        "  patch_map = [\n",
        "              [0, 1, 2, 3, 4, 5, 6, 7], # Piano\n",
        "              [24, 25, 26, 27, 28, 29, 30], # Guitar\n",
        "              [32, 33, 34, 35, 36, 37, 38, 39], # Bass\n",
        "              [40, 41], # Violin\n",
        "              [42, 43], # Cello\n",
        "              [46], # Harp\n",
        "              [56, 57, 58, 59, 60], # Trumpet\n",
        "              [64, 65, 66, 67, 68, 69, 70, 71], # Sax\n",
        "              [72, 73, 74, 75, 76, 77, 78], # Flute\n",
        "              [-1], # Drums\n",
        "              [52, 53], # Choir\n",
        "              [16, 17, 18, 19, 20] # Organ\n",
        "              ]\n",
        "\n",
        "  while itrack < len(score):\n",
        "    for event in score[itrack]:\n",
        "        if event[0] == 'note' or event[0] == 'patch_change':\n",
        "            events_matrix.append(event)\n",
        "    itrack += 1\n",
        "\n",
        "  events_matrix.sort(key=lambda x: x[1])\n",
        "\n",
        "  events_matrix1 = []\n",
        "\n",
        "  for event in events_matrix:\n",
        "    if event[0] == 'patch_change':\n",
        "        patches[event[2]] = event[3]\n",
        "\n",
        "    if event[0] == 'note':\n",
        "        event.extend([patches[event[3]]])\n",
        "        once = False\n",
        "\n",
        "        for p in patch_map:\n",
        "            if event[6] in p and event[3] != 9: # Except the drums\n",
        "                event[3] = patch_map.index(p)\n",
        "                once = True\n",
        "\n",
        "        if not once and event[3] != 9: # Except the drums\n",
        "            event[3] = 15 # All other instruments/patches channel\n",
        "            event[5] = max(80, event[5])\n",
        "\n",
        "        if event[3] < 12: # We won't write chans 12-16 for now...\n",
        "            events_matrix1.append(event)\n",
        "\n",
        "  #=======================================================\n",
        "  # PRE-PROCESSING\n",
        "\n",
        "  # checking number of instruments in a composition\n",
        "  instruments_list_without_drums = list(set([y[3] for y in events_matrix1 if y[3] != 9]))\n",
        "\n",
        "  if len(events_matrix1) > 0 and len(instruments_list_without_drums) > 0:\n",
        "\n",
        "    # recalculating timings\n",
        "    for e in events_matrix1:\n",
        "        e[1] = int(e[1] / 10) # Max 1 seconds for start-times\n",
        "        e[2] = int(e[2] / 20) # Max 2 seconds for durations\n",
        "\n",
        "    # Sorting by pitch, then by start-time\n",
        "    events_matrix1.sort(key=lambda x: x[4], reverse=True)\n",
        "    events_matrix1.sort(key=lambda x: x[1])\n",
        "\n",
        "    #=======================================================\n",
        "    # FINAL PRE-PROCESSING\n",
        "\n",
        "    melody_chords = []\n",
        "\n",
        "    pe = events_matrix1[0]\n",
        "\n",
        "    for e in events_matrix1:\n",
        "      if e[1] >= 0 and e[2] >= 0:\n",
        "\n",
        "        # Cliping all values...\n",
        "        tim = max(0, min(127, e[1]-pe[1]))\n",
        "        dur = max(1, min(127, e[2]))\n",
        "        cha = max(0, min(11, e[3]))\n",
        "        ptc = max(1, min(127, e[4]))\n",
        "        vel = max(8, min(127, e[5]))\n",
        "\n",
        "        velocity = round(vel / 15)\n",
        "\n",
        "        # Writing final note\n",
        "        melody_chords.append([tim, dur, cha, ptc, velocity])\n",
        "\n",
        "        pe = e\n",
        "\n",
        "  instruments_list = list(set([y[2] for y in melody_chords]))\n",
        "  num_instr = len(instruments_list)\n",
        "\n",
        "  #=======================================================\n",
        "  # FINAL PROCESSING\n",
        "  #=======================================================\n",
        "\n",
        "  # Break between compositions / Intro seq\n",
        "\n",
        "  if 9 in instruments_list:\n",
        "    drums_present = 2818 # Yes\n",
        "  else:\n",
        "    drums_present = 2817 # No\n",
        "\n",
        "  melody_chords_f.extend([2816, drums_present, 2819+(num_instr-1)])\n",
        "\n",
        "  #=======================================================\n",
        "\n",
        "  # Composition control seq\n",
        "  intro_mode_time = statistics.mode([0] + [y[0] for y in melody_chords if y[2] != 9 and y[0] != 0])\n",
        "  intro_mode_dur = statistics.mode([y[1] for y in melody_chords if y[2] != 9])\n",
        "  intro_mode_pitch = statistics.mode([y[3] for y in melody_chords if y[2] != 9])\n",
        "  intro_mode_velocity = statistics.mode([y[4] for y in melody_chords if y[2] != 9])\n",
        "\n",
        "  # Instrument value 12 is reserved for composition control seq\n",
        "  intro_dur_vel = (intro_mode_dur * 8) + (intro_mode_velocity-1)\n",
        "  intro_cha_ptc = (12 * 128) + intro_mode_pitch\n",
        "\n",
        "  melody_chords_f.extend([intro_mode_time, intro_dur_vel+128, intro_cha_ptc+1152])\n",
        "\n",
        "  # TOTAL DICTIONARY SIZE 2831\n",
        "\n",
        "  #=======================================================\n",
        "  # MAIN PROCESSING CYCLE\n",
        "  #=======================================================\n",
        "\n",
        "  for m in melody_chords:\n",
        "\n",
        "    # WRITING EACH NOTE HERE\n",
        "    dur_vel = (m[1] * 8) + (m[4]-1)\n",
        "    cha_ptc = (m[2] * 128) + m[3]\n",
        "\n",
        "    melody_chords_f.extend([m[0], dur_vel+128, cha_ptc+1152])\n",
        "    melody_chords_f1.append([m[0], dur_vel+128, cha_ptc+1152])\n",
        "\n",
        "  melody_chords_f1 = melody_chords_f1[:(number_of_prime_tokens // 3)]\n",
        "  melody_chords_f = melody_chords_f[:number_of_prime_tokens]\n",
        "\n",
        "  #=======================================================\n",
        "\n",
        "  song = melody_chords_f\n",
        "  song_f = []\n",
        "  tim = 0\n",
        "  dur = 0\n",
        "  vel = 0\n",
        "  pitch = 0\n",
        "  channel = 0\n",
        "\n",
        "  son = []\n",
        "  song1 = []\n",
        "\n",
        "  for s in song:\n",
        "    if s >= 128 and s < (12*128)+1152:\n",
        "      son.append(s)\n",
        "    else:\n",
        "      if len(son) == 3:\n",
        "        song1.append(son)\n",
        "      son = []\n",
        "      son.append(s)\n",
        "\n",
        "  for ss in song1:\n",
        "\n",
        "    tim += ss[0] * 10\n",
        "\n",
        "    dur = ((ss[1]-128) // 8) * 20\n",
        "    vel = (((ss[1]-128) % 8)+1) * 15\n",
        "\n",
        "    channel = (ss[2]-1152) // 128\n",
        "    pitch = (ss[2]-1152) % 128\n",
        "\n",
        "    song_f.append(['note', tim, dur, channel, pitch, vel ])\n",
        "\n",
        "  detailed_stats = TMIDIX.Tegridy_ms_SONG_to_MIDI_Converter(song_f,\n",
        "                                                            output_signature = 'Los Angeles Music Composer',\n",
        "                                                            output_file_name = '/content/Los-Angeles-Music-Composer-Seed-Composition',\n",
        "                                                            track_name='Project Los Angeles',\n",
        "                                                            list_of_MIDI_patches=[0, 24, 32, 40, 42, 46, 56, 71, 73, 0, 53, 19, 0, 0, 0, 0]\n",
        "                                                            )\n",
        "\n",
        "  #=======================================================\n",
        "\n",
        "  print('=' * 70)\n",
        "  print('Composition stats:')\n",
        "  print('Composition has', len(melody_chords_f1), 'notes')\n",
        "  print('Composition has', len(melody_chords_f), 'tokens')\n",
        "  print('=' * 70)\n",
        "\n",
        "  print('Displaying resulting composition...')\n",
        "  print('=' * 70)\n",
        "\n",
        "  fname = '/content/Los-Angeles-Music-Composer-Seed-Composition'\n",
        "\n",
        "  x = []\n",
        "  y =[]\n",
        "  c = []\n",
        "\n",
        "  colors = ['red', 'yellow', 'green', 'cyan', 'blue', 'pink', 'orange', 'purple', 'gray', 'white', 'gold', 'silver']\n",
        "\n",
        "  block_lines = [(song_f[-1][1] / 1000)]\n",
        "  block_tokens = [min(len(melody_chords_f), number_of_prime_tokens)]\n",
        "\n",
        "  for s in song_f:\n",
        "    x.append(s[1] / 1000)\n",
        "    y.append(s[4])\n",
        "    c.append(colors[s[3]])\n",
        "\n",
        "  if render_MIDI_to_audio:\n",
        "    FluidSynth(\"/usr/share/sounds/sf2/FluidR3_GM.sf2\", 16000).midi_to_audio(str(fname + '.mid'), str(fname + '.wav'))\n",
        "    display(Audio(str(fname + '.wav'), rate=16000))\n",
        "\n",
        "  plt.figure(figsize=(14,5))\n",
        "  ax=plt.axes(title=fname)\n",
        "  ax.set_facecolor('black')\n",
        "\n",
        "  plt.scatter(x,y, c=c)\n",
        "  plt.xlabel(\"Time\")\n",
        "  plt.ylabel(\"Pitch\")\n",
        "  plt.show()\n",
        "\n",
        "else:\n",
        "  print('=' * 70)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "XGQi15DfVU_a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# (COMPOSITION LOOP)\n",
        "\n",
        "## Run the cells below in a loop to generate endless continuation"
      ],
      "metadata": {
        "id": "7xNyANjZsCOi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dkvXYwR_qSnx",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Standard  Continuation Generator\n",
        "number_of_tokens_to_generate = 120 # @param {type:\"slider\", min:33, max:1023, step:3}\n",
        "number_of_batches_to_generate = 4 #@param {type:\"slider\", min:1, max:16, step:1}\n",
        "preview_length_in_tokens = 120 # @param {type:\"slider\", min:33, max:240, step:3}\n",
        "number_of_memory_tokens = 4095 #@param {type:\"slider\", min:402, max:4095, step:3}\n",
        "temperature = 1 #@param {type:\"slider\", min:0.1, max:1, step:0.1}\n",
        "render_MIDI_to_audio = True # @param {type:\"boolean\"}\n",
        "\n",
        "print('=' * 70)\n",
        "print('Los Angeles Music Composer Standard Continuation Model Generator')\n",
        "print('=' * 70)\n",
        "\n",
        "preview = melody_chords_f[-preview_length_in_tokens:]\n",
        "\n",
        "inp = [melody_chords_f[-number_of_memory_tokens:]] * number_of_batches_to_generate\n",
        "\n",
        "inp = torch.LongTensor(inp).cuda()\n",
        "\n",
        "with ctx:\n",
        "  out = model.module.generate(inp,\n",
        "                              number_of_tokens_to_generate,\n",
        "                              temperature=temperature,\n",
        "                              return_prime=False,\n",
        "                              verbose=True)\n",
        "\n",
        "out0 = out.tolist()\n",
        "\n",
        "print('=' * 70)\n",
        "print('Done!')\n",
        "\n",
        "#======================================================================\n",
        "print('=' * 70)\n",
        "print('Rendering results...')\n",
        "\n",
        "for i in range(number_of_batches_to_generate):\n",
        "\n",
        "  print('=' * 70)\n",
        "  print('Batch #', i)\n",
        "  print('=' * 70)\n",
        "\n",
        "  out1 = out0[i]\n",
        "\n",
        "  print('Sample INTs', out1[:12])\n",
        "  print('=' * 70)\n",
        "\n",
        "  if len(out) != 0:\n",
        "\n",
        "      song = preview + out1\n",
        "      song_f = []\n",
        "      tim = 0\n",
        "      dur = 0\n",
        "      vel = 0\n",
        "      pitch = 0\n",
        "      channel = 0\n",
        "\n",
        "      son = []\n",
        "      song1 = []\n",
        "\n",
        "      for s in song:\n",
        "        if s >= 128 and s < (12*128)+1152:\n",
        "          son.append(s)\n",
        "        else:\n",
        "          if len(son) == 3:\n",
        "            song1.append(son)\n",
        "          son = []\n",
        "          son.append(s)\n",
        "\n",
        "      for ss in song1:\n",
        "\n",
        "        tim += ss[0] * 10\n",
        "\n",
        "        dur = ((ss[1]-128) // 8) * 20\n",
        "        vel = (((ss[1]-128) % 8)+1) * 15\n",
        "\n",
        "        channel = (ss[2]-1152) // 128\n",
        "        pitch = (ss[2]-1152) % 128\n",
        "\n",
        "        song_f.append(['note', tim, dur, channel, pitch, vel ])\n",
        "\n",
        "      detailed_stats = TMIDIX.Tegridy_ms_SONG_to_MIDI_Converter(song_f,\n",
        "                                                            output_signature = 'Los Angeles Music Composer',\n",
        "                                                            output_file_name = '/content/Los-Angeles-Music-Composer-Music-Composition_'+str(i),\n",
        "                                                            track_name='Project Los Angeles',\n",
        "                                                            list_of_MIDI_patches=[0, 24, 32, 40, 42, 46, 56, 71, 73, 0, 53, 19, 0, 0, 0, 0]\n",
        "                                                            )\n",
        "      print('=' * 70)\n",
        "      print('Displaying resulting composition...')\n",
        "      print('=' * 70)\n",
        "\n",
        "      fname = '/content/Los-Angeles-Music-Composer-Music-Composition_'+str(i)\n",
        "\n",
        "      x = []\n",
        "      y =[]\n",
        "      c = []\n",
        "\n",
        "      colors = ['red', 'yellow', 'green', 'cyan', 'blue', 'pink', 'orange', 'purple', 'gray', 'white', 'gold', 'silver']\n",
        "\n",
        "      for s in song_f:\n",
        "        x.append(s[1] / 1000)\n",
        "        y.append(s[4])\n",
        "        c.append(colors[s[3]])\n",
        "\n",
        "      if render_MIDI_to_audio:\n",
        "        FluidSynth(\"/usr/share/sounds/sf2/FluidR3_GM.sf2\", 16000).midi_to_audio(str(fname + '.mid'), str(fname + '.wav'))\n",
        "        display(Audio(str(fname + '.wav'), rate=16000))\n",
        "\n",
        "      plt.figure(figsize=(14,5))\n",
        "      ax=plt.axes(title=fname)\n",
        "      ax.set_facecolor('black')\n",
        "\n",
        "      plt.scatter(x,y, c=c)\n",
        "\n",
        "      pbl = song_f[(int(preview_length_in_tokens / 3))][1] / 1000\n",
        "\n",
        "      ax.axvline(x=pbl, c='w')\n",
        "\n",
        "      plt.xlabel(\"Time\")\n",
        "      plt.ylabel(\"Pitch\")\n",
        "      plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Choose one generated block to add to the composition\n",
        "block_action = \"add_last_generated_block\" #@param [\"add_last_generated_block\", \"remove_last_added_block\"]\n",
        "add_block_with_batch_number = 0 #@param {type:\"slider\", min:0, max:15, step:1}\n",
        "render_MIDI_to_audio = False # @param {type:\"boolean\"}\n",
        "\n",
        "print('=' * 70)\n",
        "\n",
        "if block_action == 'add_last_generated_block':\n",
        "  melody_chords_f.extend(out0[min(len(out0)-1, add_block_with_batch_number)])\n",
        "  print('Block added!')\n",
        "else:\n",
        "  if len(block_tokens) > 1:\n",
        "    melody_chords_f = melody_chords_f[:(len(melody_chords_f)-block_tokens[-1])]\n",
        "    print('Block removed!')\n",
        "  else:\n",
        "    print('Nothing to remove!!!')\n",
        "\n",
        "print('=' * 70)\n",
        "print('Composition now has', (len(melody_chords_f) // 4), 'notes')\n",
        "print('Composition now has', len(melody_chords_f), 'tokens')\n",
        "\n",
        "\n",
        "print('=' * 70)\n",
        "print('Sample INTs', out1[:12])\n",
        "print('=' * 70)\n",
        "\n",
        "if len(melody_chords_f) != 0:\n",
        "\n",
        "    song = melody_chords_f\n",
        "    song_f = []\n",
        "    tim = 0\n",
        "    dur = 0\n",
        "    vel = 0\n",
        "    pitch = 0\n",
        "    channel = 0\n",
        "\n",
        "    son = []\n",
        "    song1 = []\n",
        "\n",
        "    for s in song:\n",
        "      if s >= 128 and s < (12*128)+1152:\n",
        "        son.append(s)\n",
        "      else:\n",
        "        if len(son) == 3:\n",
        "          song1.append(son)\n",
        "        son = []\n",
        "        son.append(s)\n",
        "\n",
        "    for ss in song1:\n",
        "\n",
        "      tim += ss[0] * 10\n",
        "\n",
        "      dur = ((ss[1]-128) // 8) * 20\n",
        "      vel = (((ss[1]-128) % 8)+1) * 15\n",
        "\n",
        "      channel = (ss[2]-1152) // 128\n",
        "      pitch = (ss[2]-1152) % 128\n",
        "\n",
        "      song_f.append(['note', tim, dur, channel, pitch, vel ])\n",
        "\n",
        "    detailed_stats = TMIDIX.Tegridy_ms_SONG_to_MIDI_Converter(song_f,\n",
        "                                                              output_signature = 'Los Angeles Music Composer',\n",
        "                                                              output_file_name = '/content/Los-Angeles-Music-Composer-Music-Composition',\n",
        "                                                              track_name='Project Los Angeles',\n",
        "                                                              list_of_MIDI_patches=[0, 24, 32, 40, 42, 46, 56, 71, 73, 0, 53, 19, 0, 0, 0, 0]\n",
        "                                                              )\n",
        "    print('=' * 70)\n",
        "    print('Displaying resulting composition...')\n",
        "    print('=' * 70)\n",
        "\n",
        "    fname = '/content/Los-Angeles-Music-Composer-Music-Composition'\n",
        "\n",
        "    x = []\n",
        "    y =[]\n",
        "    c = []\n",
        "\n",
        "    colors = ['red', 'yellow', 'green', 'cyan', 'blue', 'pink', 'orange', 'purple', 'gray', 'white', 'gold', 'silver']\n",
        "\n",
        "    if block_action == 'add_last_generated_block':\n",
        "      block_lines.append((song_f[-1][1] / 1000))\n",
        "      block_tokens.append(len(out0[min(len(out0)-1, add_block_with_batch_number)]))\n",
        "    else:\n",
        "      if len(block_tokens) > 1:\n",
        "        block_lines.pop()\n",
        "        block_tokens.pop()\n",
        "\n",
        "    for s in song_f:\n",
        "      x.append(s[1] / 1000)\n",
        "      y.append(s[4])\n",
        "      c.append(colors[s[3]])\n",
        "\n",
        "    if render_MIDI_to_audio:\n",
        "      FluidSynth(\"/usr/share/sounds/sf2/FluidR3_GM.sf2\", 16000).midi_to_audio(str(fname + '.mid'), str(fname + '.wav'))\n",
        "      display(Audio(str(fname + '.wav'), rate=16000))\n",
        "\n",
        "    plt.figure(figsize=(14,5))\n",
        "    ax=plt.axes(title=fname)\n",
        "    ax.set_facecolor('black')\n",
        "\n",
        "    plt.scatter(x,y, c=c)\n",
        "\n",
        "    for bl in block_lines:\n",
        "      ax.axvline(x=bl, c='w')\n",
        "\n",
        "    plt.xlabel(\"Time\")\n",
        "    plt.ylabel(\"Pitch\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "3YdlOR_9TdYX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Congrats! You did it! :)"
      ],
      "metadata": {
        "id": "eoWDEy6CwDr6"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuClass": "premium",
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}